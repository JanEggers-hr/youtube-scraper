{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/youtube-scraper/blob/main/whisper_audio_conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnkbc476IMEf"
      },
      "source": [
        "# Whisper-based audio-to-text conversion\n",
        "\n",
        "Runs OpenAI's \"Whisper\" TTS library in a Colab. Nothing is uploaded to OpenAI's servers, everything is processed within the Colab (e.g. in the Google Cloud).\n",
        "\n",
        "You are asked to upload a file, then the file is converted to a .txt file and downloaded to your download folder.\n",
        "\n",
        "Whisper needs MP4 files, so MP3 are converted first.\n",
        "\n",
        "## Tips for running this colab\n",
        "\n",
        "- Activate the GPU in the colab environment (menu \"Runtime\"/\"Change Runtime type\") - this speeds up the Whisper conversion immensely\n",
        "- Use a browser plugin like [Colab Auto Clicker](https://addons.mozilla.org/en-US/firefox/addon/colab-automatic-clicker/) for Firefox to hold the connection to the Notebook while it's doing the work, and leave the browser tab open\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBKJ8nokdI9z"
      },
      "source": [
        "\n",
        "\n",
        "Using the medium-sized model (the multilanguage model is about 5GB); for better accuracy, switch to \"large\" (10GB), for faster transcription, use \"small\" (2GB).\n",
        "\n",
        "Remember to switch on the GPU in Colab, or conversion will be really, really slow. **But even with GPU installed, the conversion takes some time** - approx. one minute for every five minutes of video with the Medium model - so be patient! If you should lose connection to the Colab VM, reconnect, and rerun the cell - it will restart with the audio files it has not converted yet only.\n",
        "\n",
        "One thing that Whisper does not do for you: insert paragraphs, line breaks, indentations, emphases. Anything that makes the text block more readable is missing. Sorry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwP0tQN_dHaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "e51d469a-bb01-43e4-9cdd-2ad47a26af70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing libraries for conversion (may take some time)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# Connect to Google Drive to export data\n",
        "import os\n",
        "print(\"Installing libraries for conversion (may take some time)\")\n",
        "!apt install ffmpeg\n",
        "!pip install git+https://github.com/openai/whisper.git > /dev/null 2>&1\n",
        "!pip install pydub  > /dev/null 2>&1\n",
        "\n",
        "output_dir = \"/content/audio/\"\n",
        "# Create output directory\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "os.chdir(output_dir)\n",
        "\n",
        "import whisper\n",
        "import pandas as pd\n",
        "model = whisper.load_model(\"medium\")\n",
        "# model = wisper.load_model(\"large\")\n",
        "\n",
        "from google.colab import files\n",
        "file_dict = files.upload()\n",
        "\n",
        "# List of all files for which there is no transcript now\n",
        "# M4A files have to exist - if there is an ID in the index but it has not been\n",
        "# downloaded, the run will fail. Run audio acquisition cells again.\n",
        "\n",
        "f = list(file_dict.keys())[0]\n",
        "fname = output_dir + \"/\" + f\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pathlib import Path\n",
        "\n",
        "# file extension, slicing away the dot\n",
        "stem, suffix_raw = os.path.splitext(fname)\n",
        "suffix = suffix_raw[1:]\n",
        "if suffix != \"m4a\":\n",
        "    #convert to M4a using pydub\n",
        "    audio = AudioSegment.from_file(fname,suffix)\n",
        "    audio.export(stem + \".m4a\", format=\"mp4\")\n",
        "    print(\"M4A-Datei generiert\")\n",
        "\n",
        "\n",
        "print(\"Starting conversion of audio to text file.\")\n",
        "txt_fname = stem + \".txt\"\n",
        "result = model.transcribe(fname)\n",
        "with open(txt_fname, 'w') as f:\n",
        "  f.write(result[\"text\"])\n",
        "\n",
        "\n",
        "print(\"Done - files converted.\")\n",
        "print(\"Saving to the download \")\n",
        "files.download(txt_fname)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-jgo83d8lOMQ"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}