{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/youtube-scraper/blob/main/youtube_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnkbc476IMEf"
      },
      "source": [
        "# Youtube-Scraper v05\n",
        "\n",
        "Get audio for all public videos from a Youtube channel/in a playlist, convert speech to text, and summarize with AI Large Language Model. All data is stored to the account's Google Drive.\n",
        "\n",
        "- Use [yt-dlp](https://github.com/yt-dlp/yt-dlp), a fork of youtube-dl, to collect all video metadata in an Excel sheet. \n",
        "- Use yt-dlp to download video' audio-only .M4A version with \"-f 140\" option (thx Cappucchino)\n",
        "- Use [OpenAI's Whisper library](https://github.com/openai/whisper) to do multi-language speech-to-text conversion\n",
        "- Use a Large Language Model to summarize the transcripts: default is [Aleph Alpha's](https://www.aleph-alpha.com/luminous) Luminous Extreme summarizer (API key necessary, incurs cost)\n",
        "\n",
        "M4A files, transcripts, and metadata with AI annotations/summaries are written to the ```output_dir``` folder defaulting to ```youtube-scraper/download``` in the Google drive. \n",
        "\n",
        "## Tips for running this colab\n",
        "\n",
        "- Activate the GPU in the colab environment (menu \"Runtime\"/\"Change Runtime type\") - this speeds up the Whisper conversion immensely\n",
        "- Use a browser plugin like [Colab Auto Clicker](https://addons.mozilla.org/en-US/firefox/addon/colab-automatic-clicker/) for Firefox to hold the connection to the Notebook while it's doing the work, and leave the browser tab open\n",
        "- Get an API key for Aleph Alpha or GPT3 - and calculate the cost before running the AI summary cells. \n",
        "\n",
        "----\n",
        "There is a Changelog and Todo/Ideas list at the end of this Notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdtS6YMkJUrx"
      },
      "source": [
        "## Target channel/playlist\n",
        "\n",
        "Put the channel/playlist to scrape here. If necessary, change the target directory as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDe-QySYJZIK"
      },
      "outputs": [],
      "source": [
        "channel_url = \"https://www.youtube.com/@audiopilz\"\n",
        "output_dir = \"/content/gdrive/MyDrive/youtube-scraper/output\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePyhkUhikQ4e"
      },
      "outputs": [],
      "source": [
        "# Get the youtube downloader module - a fork of youtube-dl which seems to be abandoned \n",
        "!pip install yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Igv3CcLucTbn"
      },
      "outputs": [],
      "source": [
        "# Connect to Google Drive to export data\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Create output directory \n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/youtube-scraper\"):\n",
        "    os.mkdir(\"/content/gdrive/MyDrive/youtube-scraper\")\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "os.chdir(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75LKL74KJd1E"
      },
      "source": [
        "As youtube-dl sometime fails with a 403 error (\"Forbidden\"), it is better to generate a list of all files to download first. Get the metadata - views, upload date, etc. - as well, and create an XLSX table file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lst9VR-CJ5SW"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals\n",
        "import yt_dlp\n",
        "import pandas as pd\n",
        "\n",
        "# Options for downloading metadata only \n",
        "ydl_opts = { \n",
        "    'quiet': 'True',\n",
        "    'skip-download': 'True'\n",
        "    }\n",
        "\n",
        "# Get the metadata\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    metadata = ydl.extract_info(channel_url, download=False) \n",
        "\n",
        "# This is very much \"dictionary of dictionaries of dictionaries\" style. \n",
        "# Found out how to unwrap by pure experimentation.  \n",
        "videos_df = pd.DataFrame(metadata['entries'], \n",
        "                         columns=[\"id\",\"upload_date\",\"description\",\n",
        "                                  \"duration\",\"view_count\",\"comment_count\",\n",
        "                                  \"like_count\",\"average_rating\",\n",
        "                                  \"availability\",\"age_limit\",\"categories\",\"tags\"])\n",
        "\n",
        "# Sort list by upload date in ascending order and save.\n",
        "videos_df.sort_values(\"upload_date\")\n",
        "videos_df.to_excel(\"video_list.xlsx\")\n",
        "print(len(videos_df),\" video IDs found in playlist/channel.\")\n",
        "videos_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbSN80GEJIP3"
      },
      "source": [
        "## Download Videos as Audio Files\n",
        "\n",
        "Yes, it's possible to download Audio only - which is of course much, much faster than getting the entire video file. \n",
        "\n",
        "This may still take so much time that your browser may close down the connection to the Colab VM.\n",
        "\n",
        "Another problem: Sometimes, the yt-dlp call returns an error, eg a \"403 Forbidden\" from Youtube. If that happens, the bulk download function calls itself again, starting off with the videos not downloaded yet. Python will stop after a couple of hundred recursions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1SbNxEP_MHB"
      },
      "outputs": [],
      "source": [
        "# Define a download function getting all URLs in a list as .m4a audio (format 140).\n",
        "# This is much faster than downloading video and converting to MP3. \n",
        "\n",
        "def download_m4a(videos_list):\n",
        "    ydl_opts = {'format': '140/bestaudio',\n",
        "                'outtmpl': '%(id)s.%(ext)s', \n",
        "                'ignore-errors': 'True'\n",
        "    }\n",
        "\n",
        "    # Empty list to collect all videos to download\n",
        "    new_urls = []\n",
        "    # Check whether audio already exists; if not, put in list. \n",
        "    for id in videos_list:\n",
        "        f = output_dir + \"/\" + id + \".m4a\"\n",
        "        if not os.path.exists(f):\n",
        "            new_urls.append(id)\n",
        "\n",
        "    if len(new_urls) > 0:\n",
        "        videos_left = len(new_urls)\n",
        "        print(videos_left,\" videos left to download...\")\n",
        "        # Give that list to the downloader. \n",
        "        # Sometimes, the download fails. Try again then. \n",
        "        try: \n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                    ydl.download(new_urls)\n",
        "        except:\n",
        "            # Retrying - call recursion\n",
        "            print(\"Retrying...\")\n",
        "            download_m4a(videos_list)\n",
        "\n",
        "    print(\"Downloaded audio of all available videos.\")\n",
        "    return(True)\n",
        "\n",
        "# Do it, man!\n",
        "download_m4a(videos_df[\"id\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkyD58v0c0kY"
      },
      "source": [
        "All audios are .M4A files in the output directory - named (id).m4a. Send them to the Speech-to-text converter now: Using [OpenAI's Whisper model/library](https://github.com/openai/whisper) which can be used locally. \n",
        "\n",
        "Whisper does a spectral-based language recognition before processing an audio. I guess it doesn't get along too well with mixed-language file but the transcriptions are fairly good. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEpDrgQoffBV"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBKJ8nokdI9z"
      },
      "source": [
        "Did installing the Whisper library work? If yes, the conversion is fairly simple: Just call whisper on the audio files. \n",
        "\n",
        "Using the medium-sized model (the multilanguage model is about 5GB); for better accuracy, switch to \"large\" (10GB), for faster transcription, use \"small\" (2GB). \n",
        "\n",
        "Remember to switch on the GPU in Colab, or conversion will be really, really slow. **But even with GPU installed, the conversion takes some time** - approx. one minute for every five minutes of video with the Medium model - so be patient! If you should lose connection to the Colab VM, reconnect, and rerun the cell - it will restart with the audio files it has not converted yet only. \n",
        "\n",
        "One thing that Whisper does not do for you: insert paragraphs, line breaks, indentations, emphases. Anything that makes the text block more readable is missing. Sorry. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wwP0tQN_dHaH"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import pandas as pd\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "# Get the Index file just in case. \n",
        "videos_df = pd.read_excel(\"video_list.xlsx\",index_col=0)\n",
        "\n",
        "# List of all files for which there is no transcript now\n",
        "new_urls = []\n",
        "for id in videos_df[\"id\"]:\n",
        "    f = output_dir + \"/\" + id + \"_transcript.txt\"\n",
        "    if not os.path.exists(f):\n",
        "        new_urls.append(id)\n",
        "i = 0\n",
        "print(len(new_urls),\" M4a files to transcribe.\")\n",
        "\n",
        "# M4A files have to exist - if there is an ID in the index but it has not been \n",
        "# downloaded, the run will fail. Run audio acquisition cells again. \n",
        "\n",
        "for id in new_urls:\n",
        "    m4a_fname = output_dir + \"/\" + id + \".m4a\"\n",
        "    txt_fname = output_dir + \"/\" + id + \"_transcript.txt\"\n",
        "\n",
        "    result = model.transcribe(m4a_fname)\n",
        "    # Write transcription to a text file\n",
        "    with open(txt_fname, 'w') as f:\n",
        "      f.write(result[\"text\"])\n",
        "    i = i + 1\n",
        "    print(i,\" - \",txt_fname,\" generated\")\n",
        "    \n",
        "\n",
        "print(\"Done - \",len(new_urls),\" files converted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNsgH38viIjc"
      },
      "source": [
        "# AI powered Summary\n",
        "\n",
        "Use an AI Large Language Model (LLM) as a summarizer, and for keyword extraction. \n",
        "\n",
        "AI LLMs are capable of doing a semantic summary. We are using a service that creates a bullet-point list for every text, reducing the text amount by about two-thirds, and making it more easily scannable.\n",
        "\n",
        "The LLM use costs about a tenth of a cent per text. You have to have a prepaid account there. \n",
        "\n",
        "### Using the Luminous Extreme LLM by Aleph Alpha\n",
        "\n",
        "Luminous Extreme, by the German startup [Aleph Alpha](https://www.aleph-alpha.com/luminous), is a LLM comparable to OpenAI's GPT-3 Curie model. It is not quite as powerful as the largest models available - no chatGPT skills here - but it features a very nice summarizer. \n",
        "\n",
        "Luminous has a maximum prompt size of 2048 tokens, approximately 600-800 words. It features a dedicated summarizer which may use something like 400 words per chunk, summarizing them to a one-line bullet point. \n",
        "\n",
        "**You need an account with Aleph Alpha, and an access token.** Write the token into a text file called ```aleph_alpha_key.txt```, and put it into the myDrive folder of your GDrive. \n",
        "\n",
        "### Keywords and paragraphs\n",
        "\n",
        "Target: Split the text files into single paragraphs (which may then be used as chunks). Reduce the summaries even further to keywords. Working on it. \n",
        "\n",
        "### ...and GPT-3? \n",
        "\n",
        "Can you use GPT-3 for all this? Of course you can. [Find a summarizer that uses GPT3-Davinci here](https://github.com/emlynoregan/newaiexp) - it has a \"sliding window\" approach.  \n",
        "\n",
        "I did my own experiments, with a sample summary for the model to learn from, and trying to use the summary of the first chunk as the example for the next chunk, providing some sort of context. \n",
        "\n",
        "My own experiments found that GPT3 is more expensive but not necessarily better, but I may have used wrong settings. This is still very much work in progress. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7OTarCUGKef"
      },
      "outputs": [],
      "source": [
        "# Get the API library from Aleph Alpha\n",
        "!pip install aleph_alpha_client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUFGqYmZKWkj"
      },
      "source": [
        "OK - now that we have established the connection, let's summarize the transcripts. \n",
        "\n",
        "**Running the summarizer some time after finishing the STT conversion:** The code may run \"from scratch\", i.e. without executing the cells above, with one exception: It expects the variable ```output_dir``` to be set. If the code below stops with an error saying that it does not know that variable, jump to the very top of this notebook, and run the first cell defining ```output_dir```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQAkvylZGj8K"
      },
      "outputs": [],
      "source": [
        "# Reload the GDrive, and get files to summarize, so that you may use this cell\n",
        "# without the previous ones. \n",
        "\n",
        "import hashlib\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Helper function to get text file\n",
        "def gettext(fname):\n",
        "    try: \n",
        "        textfile = open(fname,'r')\n",
        "    except:\n",
        "        print(\"**Datei \",fname,\" nicht gefunden!**\")\n",
        "        return(\"\")\n",
        "    text = textfile.readline()\n",
        "    textfile.close()\n",
        "    return(text.replace(\"\\n\",\"\"))\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path = output_dir\n",
        "os.chdir(path)\n",
        "\n",
        "# Get Alep Alpha access token first\n",
        "aa_token = gettext('/content/gdrive/MyDrive/aleph_alpha_key.txt')\n",
        "\n",
        "# Use the token to load the model\n",
        "# Boilerplate code on https://github.com/Aleph-Alpha/examples/\n",
        "from aleph_alpha_client import AlephAlphaModel, SummarizationRequest, EvaluationRequest, Document\n",
        "\n",
        "model = AlephAlphaModel.from_model_name(model_name=\"luminous-extended\", token = aa_token)\n",
        "\n",
        "print(\"AlephAlpha Token (MD5) \", hashlib.md5(aa_token.encode('utf-8')).hexdigest(),\" works.\")\n",
        "\n",
        "# Function to summarize code. \n",
        "def generate_summary(id: str):\n",
        "    text = gettext(path + \"/\" + id + \"_transcript.txt\")\n",
        "    request = SummarizationRequest(document=Document.from_text(text))\n",
        "    result = model.summarize(request)\n",
        "    print(text[:60],\"... condensed to \",len(result.summary),\" chars\")\n",
        "    return result.summary\n",
        "\n",
        "# get the index file again\n",
        "videos_df = pd.read_excel(\"video_list.xlsx\",index_col=0)\n",
        "videos_df.sort_values(\"upload_date\",ascending=True)\n",
        "\n",
        "# Summaries for every line of the index file\n",
        "videos_df[\"summary\"] = videos_df[\"id\"].map(generate_summary)\n",
        "\n",
        "videos_df.head(10)\n",
        "videos_df.to_excel(\"video_liste_annotiert.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jgo83d8lOMQ"
      },
      "source": [
        "### Changelog\n",
        "\n",
        "* v05 - Changed notebook language to English; switch downloader from youtoube-dl to yt-dlp fork, add check if availability of videos is public\n",
        "* v04 - Variablen like_count in Übersicht aufgenommen\n",
        "* v03 - Zusammenfassungen über Aleph Alpha und GPT-3 integriert; Sortierung aufsteigend nach Datum\n",
        "* v02 - Fehler beim Download automatisch auffangen (ganz simpel: Download nochmal starten)\n",
        "* v01 - Suche nach noch nicht heruntergeladenen Videos; Vervollständigung\n",
        "* v00 - Funktioniert\n",
        "\n",
        "### Todo\n",
        "\n",
        "- Better format for summary\n",
        "- Keywords, semantic similarity to focus summary"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-jgo83d8lOMQ"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
