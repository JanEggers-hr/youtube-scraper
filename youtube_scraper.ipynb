{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/youtube-scraper/blob/main/youtube_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnkbc476IMEf"
      },
      "source": [
        "# Youtube-Scraper v05\n",
        "\n",
        "Get audio for all public videos from a Youtube channel/in a playlist, convert speech to text, and summarize with AI Large Language Model. All data is stored to the account's Google Drive.\n",
        "\n",
        "- Use [yt-dlp](https://github.com/yt-dlp/yt-dlp), a fork of youtube-dl, to collect all video metadata in an Excel sheet. \n",
        "- Use yt-dlp to download video MP3 with \"-f 140\" option (thx Cappucchino)\n",
        "- Use [OpenAI's Whisper library](https://github.com/openai/whisper) to do multi-language speech-to-text conversion\n",
        "- Use a Large Language Model to summarize the transcripts: default is [Aleph Alpha's](https://www.aleph-alpha.com/luminous) Luminous Extreme summarizer (API key necessary, incurs cost)\n",
        "\n",
        "MP3 files, transcripts, and metadata with AI annotations/summaries are written to a folder ```youtube-scraper/download``` in the Google drive. \n",
        "\n",
        "## Tips for running this colab\n",
        "\n",
        "- Activate the GPU in the colab environment (menu \"Runtime\"/\"Change Runtime type\") - this speeds up the Whisper conversion immensely\n",
        "- Use a browser plugin like [Colab Auto Clicker](https://addons.mozilla.org/en-US/firefox/addon/colab-automatic-clicker/) for Firefox to hold the connection to the Notebook while it's doing the work, and leave the browser tab open\n",
        "- Get an API key for Aleph Alpha or GPT3 - and calculate the cost before running the AI summary cells. \n",
        "\n",
        "----\n",
        "There is a Changelog and Todo/Ideas list at the end of this Notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdtS6YMkJUrx"
      },
      "source": [
        "## Target channel/playlist\n",
        "\n",
        "Put the channel/playlist to scrape here. If necessary, change the target directory as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDe-QySYJZIK"
      },
      "outputs": [],
      "source": [
        "channel_url = \"https://www.youtube.com/@AudioPilz\"\n",
        "output_dir = \"/content/gdrive/MyDrive/youtube-scraper/output\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePyhkUhikQ4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f90b45-b3c8-4041-9012-510e5483ec99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.8/dist-packages (2023.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from yt-dlp) (2022.12.7)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.8/dist-packages (from yt-dlp) (10.4)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.8/dist-packages (from yt-dlp) (1.0.9)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.8/dist-packages (from yt-dlp) (3.16.0)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.8/dist-packages (from yt-dlp) (1.46.0)\n"
          ]
        }
      ],
      "source": [
        "# Get the youtube downloader module - a fork of youtube-dl which seems to be abandoned \n",
        "!pip install yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Igv3CcLucTbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884eae74-9ec1-4061-a689-d1ccfb94089f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Connect to Google Drive to export data\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Create output directory \n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/youtube-scraper\"):\n",
        "    os.mkdir(\"/content/gdrive/MyDrive/youtube-scraper\")\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "os.chdir(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75LKL74KJd1E"
      },
      "source": [
        "As youtube-dl sometime fails with a 403 error (\"Forbidden\"), it is better to generate a list of all files to download first. Get the metadata - views, upload date, etc. - as well, and create an XLSX table file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lst9VR-CJ5SW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "b23d76b1-324a-4b86-b21f-af9240a47bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179  Videos found in playlist/channel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id upload_date                                        description  \\\n",
              "0  UZi6twRFnjc    20221230  Become a Patron and get access to music clips ...   \n",
              "1  YSpmAl5yME8    20221223  Become a Patron and get access to music clips ...   \n",
              "2  da-A04Jj_8g    20221216  Become a Patron and get access to music clips ...   \n",
              "3  kD90KnHpSs0    20221209  Become a Patron and get access to music clips ...   \n",
              "4  DVGrbVXQiOE    20221202  Become a Patron and get access to music clips ...   \n",
              "\n",
              "   duration  view_count  like_count average_rating  age_limit categories  \\\n",
              "0       649       85055        4577           None          0    [Music]   \n",
              "1       624       77093        6292           None          0    [Music]   \n",
              "2       502       45873        3086           None          0    [Music]   \n",
              "3       581       82571        3720           None          0    [Music]   \n",
              "4       536       46338        2318           None          0    [Music]   \n",
              "\n",
              "                                                tags  \n",
              "0  [bad gear, behringer model d, model d, moog mo...  \n",
              "1  [bad gear, fruity loops, fl studio, meme daw, ...  \n",
              "2  [bad gear, roland tr-626, audiopilz, vintage d...  \n",
              "3  [bad gear, roland jp-8080, roland jp8080, rola...  \n",
              "4  [bad gear, roland aira j-6, audiopilz, roland ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7007e32-4022-49bc-876f-d50aa6491a59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>upload_date</th>\n",
              "      <th>description</th>\n",
              "      <th>duration</th>\n",
              "      <th>view_count</th>\n",
              "      <th>like_count</th>\n",
              "      <th>average_rating</th>\n",
              "      <th>age_limit</th>\n",
              "      <th>categories</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UZi6twRFnjc</td>\n",
              "      <td>20221230</td>\n",
              "      <td>Become a Patron and get access to music clips ...</td>\n",
              "      <td>649</td>\n",
              "      <td>85055</td>\n",
              "      <td>4577</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>[Music]</td>\n",
              "      <td>[bad gear, behringer model d, model d, moog mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>YSpmAl5yME8</td>\n",
              "      <td>20221223</td>\n",
              "      <td>Become a Patron and get access to music clips ...</td>\n",
              "      <td>624</td>\n",
              "      <td>77093</td>\n",
              "      <td>6292</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>[Music]</td>\n",
              "      <td>[bad gear, fruity loops, fl studio, meme daw, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>da-A04Jj_8g</td>\n",
              "      <td>20221216</td>\n",
              "      <td>Become a Patron and get access to music clips ...</td>\n",
              "      <td>502</td>\n",
              "      <td>45873</td>\n",
              "      <td>3086</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>[Music]</td>\n",
              "      <td>[bad gear, roland tr-626, audiopilz, vintage d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kD90KnHpSs0</td>\n",
              "      <td>20221209</td>\n",
              "      <td>Become a Patron and get access to music clips ...</td>\n",
              "      <td>581</td>\n",
              "      <td>82571</td>\n",
              "      <td>3720</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>[Music]</td>\n",
              "      <td>[bad gear, roland jp-8080, roland jp8080, rola...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DVGrbVXQiOE</td>\n",
              "      <td>20221202</td>\n",
              "      <td>Become a Patron and get access to music clips ...</td>\n",
              "      <td>536</td>\n",
              "      <td>46338</td>\n",
              "      <td>2318</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>[Music]</td>\n",
              "      <td>[bad gear, roland aira j-6, audiopilz, roland ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7007e32-4022-49bc-876f-d50aa6491a59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7007e32-4022-49bc-876f-d50aa6491a59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7007e32-4022-49bc-876f-d50aa6491a59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from __future__ import unicode_literals\n",
        "import yt_dlp\n",
        "import pandas as pd\n",
        "\n",
        "# Options for downloading metadata only \n",
        "ydl_opts = { \n",
        "    'quiet': 'True',\n",
        "    'skip-download': 'True'\n",
        "    }\n",
        "\n",
        "# Get the metadata\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    metadata = ydl.extract_info(channel_url, download=False) \n",
        "\n",
        "# This is very much \"dictionary of dictionaries of dictionaries\" style. \n",
        "# Found out how to unwrap by pure experimentation.  \n",
        "videos_df = pd.DataFrame(metadata['entries'][0]['entries'], columns=[\"id\",\"upload_date\",\"description\",\"duration\",\"view_count\",\"like_count\",\n",
        "                                                                      \"average_rating\",\n",
        "                                                                     \"age_limit\",\"categories\",\"tags\"])\n",
        "\n",
        "# Sort list by upload date in ascending order and save.\n",
        "videos_df.sort_values(\"upload_date\")\n",
        "videos_df.to_excel(\"video_list.xlsx\")\n",
        "print(len(videos_df),\" video IDs found in playlist/channel.\")\n",
        "videos_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbSN80GEJIP3"
      },
      "source": [
        "## Videos herunterladen\n",
        "\n",
        "*ACHTUNG*: Dieser Schritt dauert eine Weile - und bricht gern mal mit einem Fehler ab, weil Youtube dem youtube-dl-Skript gerne mal ein \"Darfste nicht!\" in den Weg wirft. **Falls youtube-dl mit einem Fehler abbricht, ruft die Funktion sich selbst noch mal neu auf.** Das stößt (zum Glück) irgendwann an Grenzen - bei zu vielen Rekursionen bricht Python ab. \n",
        "\n",
        "Dummerweise verliert das Colab-Notebook nach einer Zeit die virtuelle Maschine, und man muss alles nochmal von vorn starten - deshalb schaut der Code, welche Videos schon heruntergeladen sind, und macht da weiter, wo es zuletzt aufgehört hat. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1SbNxEP_MHB"
      },
      "outputs": [],
      "source": [
        "# Define a download function getting all URLs in a list as .m4a audio (format 140).\n",
        "# This is much faster than downloading video and converting to MP3. \n",
        "\n",
        "def download_m4a(videos_list):\n",
        "    ydl_opts = {'format': '140/bestaudio',\n",
        "                'outtmpl': '%(id)s.%(ext)s', \n",
        "    }\n",
        "\n",
        "    # Leere Liste anlegen\n",
        "    new_urls = []\n",
        "    # Check whether audio already exists; if not, put in list. \n",
        "    for id in videos_list:\n",
        "        f = path + \"/\" + id + \".m4a\"\n",
        "        if not os.path.exists(f):\n",
        "            new_urls.append(id)\n",
        "\n",
        "    if len(new_urls) > 0:\n",
        "        print(len(new_urls),\" videos left to download...\")\n",
        "        # Give that list to the downloader. \n",
        "        # Sometimes, the download fails. Try again then. \n",
        "        try: \n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                    ydl.download(new_urls)\n",
        "        except:\n",
        "            # Retrying - call recursion\n",
        "            print(\"Retrying...\")\n",
        "            download_m4a(videos_liste)\n",
        "\n",
        "    print(\"Downloaded audio of all available videos.\")\n",
        "    return(True)\n",
        "\n",
        "# Jetzt die Funktion ausführen\n",
        "download_m4a(videos_df[\"id\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkyD58v0c0kY"
      },
      "source": [
        "All audios are .M4A files in the output directory - named (id).m4a. Send them to the Speech-to-text converter now: Using [OpenAI's Whisper model/library](https://github.com/openai/whisper) which can be used locally. \n",
        "\n",
        "Whisper does a spectral-based language recognition before processing an audio. I guess it doesn't get along too well with mixed-language file but the transcriptions are fairly good. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEpDrgQoffBV"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBKJ8nokdI9z"
      },
      "source": [
        "Did installing the Whisper library work? If yes, the conversion is fairly simple: Just call whisper on the audio files. \n",
        "\n",
        "Using the medium-sized model (the multilanguage model is about 5GB); for better accuracy, switch to \"large\" (10GB), for faster transcription, use \"small\" (2GB). \n",
        "\n",
        "Remember to switch on the GPU in Colab, or conversion will be really, really slow. \n",
        "\n",
        "One thing that Whisper does not do for you: insert paragraphs, line breaks, indentations, emphases. Anything that makes the text block more readable is missing. Sorry. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwP0tQN_dHaH"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import pandas as pd\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "# Get the Index file just in case. \n",
        "videos_df = pd.read_excel(\"video_list.xlsx\",index_col=0)\n",
        "\n",
        "# List of all files for which there is no transcript now\n",
        "new_urls = []\n",
        "for id in videos_df[\"id\"]:\n",
        "    f = path + \"/\" + id + \"_transcript.txt\"\n",
        "    if not os.path.exists(f):\n",
        "        new_urls.append(id)\n",
        "i = 0\n",
        "print(len(new_urls),\" M4a files to transcribe.\")\n",
        "\n",
        "# M4A files have to exist - if there is an ID in the index but it has not been \n",
        "# downloaded, the run will fail. Run audio acquisition cells again. \n",
        "\n",
        "for id in new_urls:\n",
        "    m4a_fname = path + \"/\" + id + \".m4a\"\n",
        "    txt_fname = path + \"/\" + id + \"_transcript.txt\"\n",
        "\n",
        "    result = model.transcribe(m4a_fname)\n",
        "    # Write transcription to a text file\n",
        "    with open(txt_fname, 'w') as f:\n",
        "      f.write(result[\"text\"])\n",
        "    i = i + 1\n",
        "    print(i,\" - \",txt_fname,\" erzeugt\")\n",
        "    \n",
        "\n",
        "print(\"Done - \",len(new_urls),\" files converted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNsgH38viIjc"
      },
      "source": [
        "# AI powered Summary\n",
        "\n",
        "Use an AI Large Language Model (LLM) as a summarizer, and for keyword extraction. \n",
        "\n",
        "AI LLMs are capable of doing a semantic summary. We are using a service that creates a bullet-point list for every text, reducing the text amount by about two-thirds, and making it more easily scannable.\n",
        "\n",
        "The LLM use costs about a tenth of a cent per text. You have to have a prepaid account there. \n",
        "\n",
        "### Using the Luminous Extreme LLM by Aleph Alpha\n",
        "\n",
        "Luminous Extreme, by the German startup [Aleph Alpha](https://www.aleph-alpha.com/luminous), is a LLM comparable to OpenAI's Curie model. It is not quite as powerful as the largest models available - no chatGPT skills here - but it features a very nice summarizer. \n",
        "\n",
        "Luminous has a maximum prompt size of 2048 tokens, approximately 600-800 words. It features a dedicated summarizer which may use something like 400 words per chunk, summarizing them to a one-line bullet point. \n",
        "\n",
        "**You need an account with Aleph Alpha, and an access token.** Write the token into a text file called ```aleph_alpha_key.txt```, and put it into the myDrive folder of your GDrive. \n",
        "\n",
        "### Keywords and paragraphs\n",
        "\n",
        "Target: Split the text files into single paragraphs (which may then be used as chunks). Reduce the summaries even further to keywords. Working on it. \n",
        "\n",
        "### ...and GPT-3? \n",
        "\n",
        "Can you use GPT-3 for all this? Of course you can. [Find a summarizer that uses GPT3-Davinci here](https://github.com/emlynoregan/newaiexp) - it has a \"sliding window\" approach.  \n",
        "\n",
        "I did my own experiments, with a sample summary for the model to learn from, and trying to use the summary of the first chunk as the example for the next chunk, providing some sort of context. \n",
        "\n",
        "My own experiments found that GPT3 is more expensive but not necessarily better, but I may have used wrong settings. This is still very much work in progress. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7OTarCUGKef"
      },
      "outputs": [],
      "source": [
        "# Get the API library from Aleph Alpha\n",
        "!pip install aleph_alpha_client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUFGqYmZKWkj"
      },
      "source": [
        "Als erstes das Token aus der Datei ```aleph_alpha_key.txt``` laden und eine Prüfsumme ausgeben. \n",
        "\n",
        "Dann die Files durch die KI-Zusammenfassung schicken und diese in die Summary. \n",
        "\n",
        "Ein wenig Experimentieren hat gezeigt: Das Modell arbeitet den Text durch und kondensiert ihn in Bullet Points, von denen nicht alle wirklich dem Text entsprechen. Experimentell wählen wir die Bulletpoints aus, die die größte semantische Ähnlichkeit mit dem Gesamttext haben. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQAkvylZGj8K"
      },
      "outputs": [],
      "source": [
        "# Falls das Colab inzwischen alles vergessen hat: \n",
        "# Alle Imports nochmal machen; Google-Drive nochmal mounten\n",
        "\n",
        "import hashlib\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Hilfsfunktion: Textdatei wieder einlesen\n",
        "def gettext(fname):\n",
        "    try: \n",
        "        textfile = open(fname,'r')\n",
        "    except:\n",
        "        print(\"**Datei \",fname,\" nicht gefunden!**\")\n",
        "        return(\"\")\n",
        "    text = textfile.readline()\n",
        "    textfile.close()\n",
        "    return(text.replace(\"\\n\",\"\"))\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path = \"/content/gdrive/MyDrive/youtube-scraper/output\"\n",
        "os.chdir(path)\n",
        "\n",
        "# Erst das Aleph-Alpha-Token holen\n",
        "aa_token = gettext('/content/gdrive/MyDrive/aleph_alpha_key.txt')\n",
        "\n",
        "# Den Key gleich nutzen, um die Modelle zu laden\n",
        "# Boilerplate-Code für Aleph Alpha von https://github.com/Aleph-Alpha/examples/ kopiert\n",
        "from aleph_alpha_client import AlephAlphaModel, SummarizationRequest, EvaluationRequest, Document\n",
        "\n",
        "model = AlephAlphaModel.from_model_name(model_name=\"luminous-extended\", token = aa_token)\n",
        "\n",
        "print(\"AlephAlpha Token (MD5) \", hashlib.md5(aa_token.encode('utf-8')).hexdigest(),\" geladen und getestet.\")\n",
        "\n",
        "# Funktion generiert eine Zusammenfassung mit dem Aleph-Alpha-Modell luminous-extended (etwa wie GPT3-Curie.)\n",
        "def generate_summary(id: str):\n",
        "    text = gettext(path + \"/\" + id + \"_transcribe.txt\")\n",
        "    request = SummarizationRequest(document=Document.from_text(text))\n",
        "    result = model.summarize(request)\n",
        "    print(text[:60],\"... zusammengefasst in \",len(result.summary),\" Zeichen\")\n",
        "    return result.summary\n",
        "\n",
        "# Index-Datei nochmal holen\n",
        "videos_df = pd.read_excel(\"video_liste.xlsx\",index_col=0)\n",
        "videos_df.sort_values(\"upload_date\",ascending=True)\n",
        "\n",
        "# Allen Index-Dateizeilen Summaries geben\n",
        "videos_df[\"summary\"] = videos_df[\"id\"].map(generate_summary)\n",
        "\n",
        "videos_df.head(10)\n",
        "videos_df.to_excel(\"video_liste_annotiert.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changelog\n",
        "\n",
        "* v05 - Changed notebook language to English; switch downloader from youtoube-dl to yt-dlp fork\n",
        "* v04 - Variablen like_count in Übersicht aufgenommen\n",
        "* v03 - Zusammenfassungen über Aleph Alpha und GPT-3 integriert; Sortierung aufsteigend nach Datum\n",
        "* v02 - Fehler beim Download automatisch auffangen (ganz simpel: Download nochmal starten)\n",
        "* v01 - Suche nach noch nicht heruntergeladenen Videos; Vervollständigung\n",
        "* v00 - Funktioniert\n",
        "\n",
        "### Todo\n",
        "\n",
        "- Better format for summary"
      ],
      "metadata": {
        "id": "-jgo83d8lOMQ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}