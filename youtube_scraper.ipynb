{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/youtube-scraper/blob/main/youtube_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnkbc476IMEf"
      },
      "source": [
        "# Youtube-Scraper v04\n",
        "\n",
        "Holt die Videos des übergebenen Youtube-Kanals, isoliert das Audio, und verschriftlicht sie mit einem Speech-to-Text-Service. \n",
        "\n",
        "Die einzelnen Schritte:\n",
        "- Mit youtube_dl nacheinander Videos holen, zu MP3 wandeln\n",
        "- Die dabei gesammelten wichtigsten Metadaten (Upload-Datum, View-Count) in einer Excel-Datei ablegen\n",
        "- Mit der OpenAI-Library \"Whisper\" in Text konvertieren\n",
        "\n",
        "Dateien liegen danach alle in einem Ordner \"output\" und müssen von da exportiert werden, weil sie sonst am Ende der Colab-Laufzeit gelöscht werden. Wär doch schade drum. \n",
        "\n",
        "## N00bwarnung\n",
        "\n",
        "Das Skript ist nicht sehr elegant, vor allem aber ist es desaströs langsam. Die youtube_dl-Library lässt sich, soweit ich das erforschen konnte, nicht asynchron ausführen, was schade ist - man könnte ja durchaus mehrere Videos gleichzeitig herunterladen. Vor allem aber könnte man sie Whisper schon mal zum Transkribieren geben. \n",
        "\n",
        "So immerhin ist alles schön einfach - wenn auch nicht schnell. \n",
        "\n",
        "## GPU einschalten!\n",
        "\n",
        "Die Whisper-Library profitiert sehr davon, wenn man im Menü unter \"Laufzeit/Laufzeittyp ändern\" die GPU aktiviert. (Auch wenn Google zunächst meckert, weil das Herunterladen der Videos ohne GPU-Nutzung abgeht.)\n",
        "\n",
        "Theoretisch könnte man vermutlich auch eine ffmpeg-Variante einbinden, die die GPU nutzt, dann geht der YT-Download schneller... aber: siehe oben. \n",
        "\n",
        "## ----\n",
        "### Changelog\n",
        "* v04 - Variablen like_count und comment_count in Übersicht aufgenommen\n",
        "* v03 - Zusammenfassungen über Aleph Alpha und GPT-3 integriert; Sortierung aufsteigend nach Datum\n",
        "* v02 - Fehler beim Download automatisch auffangen (ganz simpel: Download nochmal starten)\n",
        "* v01 - Suche nach noch nicht heruntergeladenen Videos; Vervollständigung\n",
        "* v00 - Funktioniert\n",
        "\n",
        "### Todo: Mögliche Verbesserungen\n",
        "\n",
        "- Publikationsdatum der Videos in den Dateinamen, um besseren Überblick zu haben\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdtS6YMkJUrx"
      },
      "source": [
        "Hier den Kanal eintragen, der gescraped werden soll - und das Zielverzeichnis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDe-QySYJZIK"
      },
      "outputs": [],
      "source": [
        "channel_url = \"https://www.youtube.com/@AudioPilz\"\n",
        "output_dir = \"/content/gdrive/MyDrive/youtube-scraper/output\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePyhkUhikQ4e"
      },
      "outputs": [],
      "source": [
        "# Vorbereitung: youtube_dl installieren\n",
        "!pip install youtube_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Igv3CcLucTbn"
      },
      "outputs": [],
      "source": [
        "# Für die Datensicherung: Drive verbinden\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Ausgabeverzeichnis output_dir anlegen: \n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/youtube-scraper\"):\n",
        "    os.mkdir(\"/content/gdrive/MyDrive/youtube-scraper\")\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "os.chdir(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75LKL74KJd1E"
      },
      "source": [
        "Mit der Library youtube_dl wird eine Liste der Videos mit Metadaten als Tabelle erstellt. Das wird vom Download getrennt, um Abbrüche auffangen zu können - manchmal scheitert youtube_dl an einem \"403 FORBIDDEN\" der Plattform. \n",
        "\n",
        "Also: in der ersten Runde nur Daten sammeln - und als XLSX exportieren. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lst9VR-CJ5SW"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals\n",
        "import youtube_dl\n",
        "import pandas as pd\n",
        "\n",
        "# Die Optionen, um neben den Metadaten gleich alle MP3-Dateien herunterzuladen: \n",
        "ydl_opts = { 'quiet': 'True' }\n",
        "\n",
        "# Erste Aufgabe: Hole Metadaten für einen Channel, keine Downloads\n",
        "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "    metadata = ydl.extract_info(channel_url, download=False) \n",
        "\n",
        "# Die Daten sind ein bisserl verschachtelt: Die URLs der Videos sind als Dictionary in einer Liste von Dictionaries oder so. Das hier funktioniert\n",
        "videos_df = pd.DataFrame(metadata['entries'][0]['entries'], columns=[\"id\",\"upload_date\",\"description\",\"duration\",\"view_count\",\"like_count\",\n",
        "                                                                      \"average_rating\",\n",
        "                                                                     \"age_limit\",\"categories\",\"tags\"])\n",
        "\n",
        "# Liste aufsteigend nach Datum sortieren und exportieren\n",
        "videos_df.sort_values(\"upload_date\")\n",
        "videos_df.to_excel(\"video_liste.xlsx\")\n",
        "print(len(videos_df),\" Videos in der Playlist/Kanal-Startseite gefunden.\")\n",
        "videos_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbSN80GEJIP3"
      },
      "source": [
        "## Videos herunterladen\n",
        "\n",
        "*ACHTUNG*: Dieser Schritt dauert eine Weile - und bricht gern mal mit einem Fehler ab, weil Youtube dem youtube-dl-Skript gerne mal ein \"Darfste nicht!\" in den Weg wirft. **Falls youtube-dl mit einem Fehler abbricht, ruft die Funktion sich selbst noch mal neu auf.** Das stößt (zum Glück) irgendwann an Grenzen - bei zu vielen Rekursionen bricht Python ab. \n",
        "\n",
        "Dummerweise verliert das Colab-Notebook nach einer Zeit die virtuelle Maschine, und man muss alles nochmal von vorn starten - deshalb schaut der Code, welche Videos schon heruntergeladen sind, und macht da weiter, wo es zuletzt aufgehört hat. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1SbNxEP_MHB"
      },
      "outputs": [],
      "source": [
        "# Definiere den Download als Funktion - die sich im Fehlerfall rekursiv neu aufruft\n",
        "\n",
        "def download_mp3(videos_liste):\n",
        "    # Die Optionen, um neben den Metadaten gleich alle MP3-Dateien herunterzuladen: \n",
        "    ydl_opts = {'format': 'bestaudio/best',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'mp3',\n",
        "        'preferredquality': '128',\n",
        "    }],\n",
        "    'outtmpl': '%(id)s.%(ext)s', # Formatiere Dateinamen: id.mp3\n",
        "    }\n",
        "\n",
        "    # Leere Liste anlegen\n",
        "    new_urls = []\n",
        "    # Videos, für die es noch kein mp3 gibt, in die Liste\n",
        "    for id in videos_liste:\n",
        "        f = path + \"/\" + id + \".mp3\"\n",
        "        if not os.path.exists(f):\n",
        "            new_urls.append(id)\n",
        "\n",
        "    if len(new_urls) > 0:\n",
        "        print(\"Noch \",len(new_urls),\" Videos herunterladen...\")\n",
        "        # Die Liste an den Downloader verfüttern.\n",
        "        # Videos werden nach dem Download in MP3 gewandelt, das\n",
        "        # bestimmen die Parameter. \n",
        "        try: \n",
        "            with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "                    ydl.download(new_urls)\n",
        "        except:\n",
        "            # Fehler geworfen; versuch es nochmal\n",
        "            print(\"Versuche es nochmal...\")\n",
        "            download_mp3(videos_liste)\n",
        "\n",
        "    print(\"Alle Videos des Kanals heruntergeladen!\")\n",
        "    return(True)\n",
        "\n",
        "# Jetzt die Funktion ausführen\n",
        "download_mp3(videos_df[\"id\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkyD58v0c0kY"
      },
      "source": [
        "Die Audios liegen alle als MP3 im Ordner output - mit den Dateinamen (id).mp3. Jetzt alle an den STT-Konverter schicken. \n",
        "\n",
        "Wir versuchen hier an dieser Stelle mal, OpenAIs \"Whisper\" einzusetzen. \n",
        "\n",
        "Quelle: https://github.com/openai/whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEpDrgQoffBV"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_excel(\"video_liste.xlsx\",index_col=0).head(5)"
      ],
      "metadata": {
        "id": "FtjWrMVFLq0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBKJ8nokdI9z"
      },
      "source": [
        "Wenn die Installation der Library von Github geklappt hat, ist die eigentliche Transkription ziemlich simpel: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwP0tQN_dHaH"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import pandas as pd\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "# Index-Datei nochmal holen\n",
        "videos_df = pd.read_excel(\"video_liste.xlsx\",index_col=0)\n",
        "\n",
        "# Wie oben: Liste von allen noch nicht konvertierten Dateien\n",
        "new_urls = []\n",
        "for id in videos_df[\"id\"]:\n",
        "    f = path + \"/\" + id + \"_transcribe.txt\"\n",
        "    if not os.path.exists(f):\n",
        "        new_urls.append(id)\n",
        "i = 0\n",
        "print(len(new_urls),\" MP3-Dateien zu verschriftlichen.\")\n",
        "\n",
        "for id in new_urls:\n",
        "    mp3_fname = path + \"/\" + id + \".mp3\"\n",
        "    txt_fname = path + \"/\" + id + \"_transcribe.txt\"\n",
        "\n",
        "    result = model.transcribe(mp3_fname)\n",
        "    # Ergebnis der Umwandlung als Textdatei ausgeben\n",
        "    with open(txt_fname, 'w') as f:\n",
        "      f.write(result[\"text\"])\n",
        "    i = i + 1\n",
        "    print(i,\" - \",txt_fname,\" erzeugt\")\n",
        "    \n",
        "\n",
        "print(\"Fertig - \",len(new_urls),\" Dateien konvertiert.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNsgH38viIjc"
      },
      "source": [
        "# KI-generierte Nachbearbeitung und Zusammenfassung\n",
        "\n",
        "Jetzt noch: eine Summary erstellen. \n",
        "\n",
        "KI-Sprachmodelle können die Textdatei in einzelne Absätze aufteilen und eine semantische Zusammenfassung erstellen. Das passiert hier - der Service kostet allerdings ein paar Zehntel Cent pro Datei.\n",
        "\n",
        "### Genutzter KI-Service: Aleph Alpha Luminous Extreme\n",
        "\n",
        "Das Skript nutzt ein Sprachmodell des deutschen Startups Aleph Alpha, um eine Zusammenfassung schreiben zu lassen. Das Zugangs-Token muss im Google-Drive liegen, im MyDrive-Wurzelverzeichnis in einer Textdatei namens ```aleph_alpha_key.txt```.\n",
        "\n",
        "Das Aleph-Alpha-Modell 'Luminous Extreme' bietet eine dedizierte Zumsammenfassungs-Funktion. Es ist eingestandenermaßen kleiner und weniger leistungsfähig als das größte GPT3-Modell Davinci; so spart man sich allerdings, einen Cloud-Dienst von OpenAI einzusetzen (was man natürlich auch kann; siehe unten). You're not paying the Man like this.\n",
        "\n",
        "### Was das Summarization-Modell macht\n",
        "\n",
        "Da die Textlänge begrenzt ist - Luminous hat eine Maximalgröße von 2048 Tokens, was etwa 600-700 Zeichen entspricht - arbeitet die Summary-Funktion mit einem gleitenden Fenster, das aber deutlich kleiner ist - vielleicht 400 Token (vermute ich). Das Modell reduziert Abschnitte auf einzelne Aufzählungspunkte; die Textmenge wird dabei etwa auf ein Drittel reduziert. \n",
        "\n",
        "### Andere Modelle machen es teurer, aber nur wenig besser\n",
        "\n",
        "Aus diesem Code in ein anderes Skript ausgelagert sind Experimente mit anderen Modellen: Kann man die Vervollständigung von Sprachmodellen wie GPT3-DaVinci oder dem größten Aleph-Alpha-Modell Luminous Supreme nutzen, um bessere Summaries zu erstellen?\n",
        "\n",
        "Dazu muss man dem Sprachmodell in der Regel ein Beispiel geben. Die Länge des nutzbaren Textfensters schrumpft also auf ca. 800 bzw. 2000 Zeichen. Außerdem zeigen erste Erfahrungen, dass es qualitativ erst dann deutlich besser wird, wenn man einen \"Best of 3\"-Ansatz wählt. Das Ganze ist also für große Video-Kanäle durchaus eine teure Angelegenheit. \n",
        "\n",
        "Deshalb - und weil die qualitative Verbesserung zwar schön ist, aber nicht lebensnotwendig - reicht an dieser Stelle die Luminous-Summary aus. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7OTarCUGKef"
      },
      "outputs": [],
      "source": [
        "# Library holen und installieren\n",
        "!pip install aleph_alpha_client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUFGqYmZKWkj"
      },
      "source": [
        "Als erstes das Token aus der Datei ```aleph_alpha_key.txt``` laden und eine Prüfsumme ausgeben. \n",
        "\n",
        "Dann die Files durch die KI-Zusammenfassung schicken und diese in die Summary. \n",
        "\n",
        "Ein wenig Experimentieren hat gezeigt: Das Modell arbeitet den Text durch und kondensiert ihn in Bullet Points, von denen nicht alle wirklich dem Text entsprechen. Experimentell wählen wir die Bulletpoints aus, die die größte semantische Ähnlichkeit mit dem Gesamttext haben. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQAkvylZGj8K"
      },
      "outputs": [],
      "source": [
        "# Falls das Colab inzwischen alles vergessen hat: \n",
        "# Alle Imports nochmal machen; Google-Drive nochmal mounten\n",
        "\n",
        "import hashlib\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Hilfsfunktion: Textdatei wieder einlesen\n",
        "def gettext(fname):\n",
        "    try: \n",
        "        textfile = open(fname,'r')\n",
        "    except:\n",
        "        print(\"**Datei \",fname,\" nicht gefunden!**\")\n",
        "        return(\"\")\n",
        "    text = textfile.readline()\n",
        "    textfile.close()\n",
        "    return(text.replace(\"\\n\",\"\"))\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path = \"/content/gdrive/MyDrive/youtube-scraper/output\"\n",
        "os.chdir(path)\n",
        "\n",
        "# Erst das Aleph-Alpha-Token holen\n",
        "aa_token = gettext('/content/gdrive/MyDrive/aleph_alpha_key.txt')\n",
        "\n",
        "# Den Key gleich nutzen, um die Modelle zu laden\n",
        "# Boilerplate-Code für Aleph Alpha von https://github.com/Aleph-Alpha/examples/ kopiert\n",
        "from aleph_alpha_client import AlephAlphaModel, SummarizationRequest, EvaluationRequest, Document\n",
        "\n",
        "model = AlephAlphaModel.from_model_name(model_name=\"luminous-extended\", token = aa_token)\n",
        "\n",
        "print(\"AlephAlpha Token (MD5) \", hashlib.md5(aa_token.encode('utf-8')).hexdigest(),\" geladen und getestet.\")\n",
        "\n",
        "# Funktion generiert eine Zusammenfassung mit dem Aleph-Alpha-Modell luminous-extended (etwa wie GPT3-Curie.)\n",
        "def generate_summary(id: str):\n",
        "    text = gettext(path + \"/\" + id + \"_transcribe.txt\")\n",
        "    request = SummarizationRequest(document=Document.from_text(text))\n",
        "    result = model.summarize(request)\n",
        "    print(text[:60],\"... zusammengefasst in \",len(result.summary),\" Zeichen\")\n",
        "    return result.summary\n",
        "\n",
        "# Index-Datei nochmal holen\n",
        "videos_df = pd.read_excel(\"video_liste.xlsx\",index_col=0)\n",
        "videos_df.sort_values(\"upload_date\",ascending=True)\n",
        "\n",
        "# Allen Index-Dateizeilen Summaries geben\n",
        "videos_df[\"summary\"] = videos_df[\"id\"].map(generate_summary)\n",
        "\n",
        "videos_df.head(10)\n",
        "videos_df.to_excel(\"video_liste_annotiert.xlsx\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}