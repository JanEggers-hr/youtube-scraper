{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanEggers-hr/youtube-scraper/blob/main/youtube_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnkbc476IMEf"
      },
      "source": [
        "# Youtube-Scraper v02\n",
        "\n",
        "Holt die Videos des übergebenen Youtube-Kanals, isoliert das Audio, und verschriftlicht sie mit einem Speech-to-Text-Service. \n",
        "\n",
        "Die einzelnen Schritte:\n",
        "- Mit youtube_dl nacheinander Videos holen, zu MP3 wandeln\n",
        "- Die dabei gesammelten wichtigsten Metadaten (Upload-Datum, View-Count) in einer Excel-Datei ablegen\n",
        "- Mit der OpenAI-Library \"Whisper\" in Text konvertieren\n",
        "\n",
        "Dateien liegen danach alle in einem Ordner \"output\" und müssen von da exportiert werden, weil sie sonst am Ende der Colab-Laufzeit gelöscht werden. Wär doch schade drum. \n",
        "\n",
        "## N00bwarnung\n",
        "\n",
        "Das Skript ist nicht sehr elegant, vor allem aber ist es desaströs langsam. Die youtube_dl-Library lässt sich, soweit ich das erforschen konnte, nicht asynchron ausführen, was schade ist - man könnte ja durchaus mehrere Videos gleichzeitig herunterladen. Vor allem aber könnte man sie Whisper schon mal zum Transkribieren geben. \n",
        "\n",
        "So immerhin ist alles schön einfach - wenn auch nicht schnell. \n",
        "\n",
        "## GPU einschalten!\n",
        "\n",
        "Die Whisper-Library profitiert sehr davon, wenn man im Menü unter \"Laufzeit/Laufzeittyp ändern\" die GPU aktiviert. (Auch wenn Google zunächst meckert, weil das Herunterladen der Videos ohne GPU-Nutzung abgeht.)\n",
        "\n",
        "Theoretisch könnte man vermutlich auch eine ffmpeg-Variante einbinden, die die GPU nutzt, dann geht der YT-Download schneller... aber: siehe oben. \n",
        "\n",
        "## ----\n",
        "### Changelog\n",
        "* v02 - Fehler beim Download automatisch auffangen (ganz simpel: Download nochmal starten)\n",
        "* v01 - Suche nach noch nicht heruntergeladenen Videos; Vervollständigung\n",
        "* v00 - Funktioniert\n",
        "\n",
        "### Todo: Mögliche Verbesserungen\n",
        "\n",
        "- Publikationsdatum der Videos in den Dateinamen, um besseren Überblick zu haben\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePyhkUhikQ4e"
      },
      "outputs": [],
      "source": [
        "# Vorbereitung: youtube_dl installieren\n",
        "!pip install youtube_dl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Für die Datensicherung: Drive verbinden\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Ausgabeverzeichnis (/gdrive/MyDrive/youtube-scraper/output) anlegen: \n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/youtube-scraper\"):\n",
        "    os.mkdir(\"/content/gdrive/MyDrive/youtube-scraper\")\n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/youtube-scraper/output\"):\n",
        "    os.mkdir(\"/content/gdrive/MyDrive/youtube-scraper/output\")\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/youtube-scraper/output\"\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "Igv3CcLucTbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdtS6YMkJUrx"
      },
      "source": [
        "Hier den Kanal eintragen, der gescraped werden soll. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDe-QySYJZIK"
      },
      "outputs": [],
      "source": [
        "channel_url = \"https://www.youtube.com/@JanEggers\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75LKL74KJd1E"
      },
      "source": [
        "Mit der Library youtube_dl wird eine Liste der Videos mit Metadaten als Tabelle erstellt. Das wird vom Download getrennt, um Abbrüche auffangen zu können - manchmal scheitert youtube_dl an einem \"403 FORBIDDEN\" der Plattform. \n",
        "\n",
        "Also: in der ersten Runde nur Daten sammeln - und als XLSX exportieren. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lst9VR-CJ5SW"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals\n",
        "import youtube_dl\n",
        "import pandas as pd\n",
        "\n",
        "# Die Optionen, um neben den Metadaten gleich alle MP3-Dateien herunterzuladen: \n",
        "ydl_opts = { 'quiet': 'True' }\n",
        "\n",
        "# Erste Aufgabe: Hole Metadaten für einen Channel, keine Downloads\n",
        "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "    metadata = ydl.extract_info(channel_url, download=False) \n",
        "\n",
        "# Die Daten sind ein bisserl verschachtelt: Die URLs der Videos sind als Dictionary in einer Liste von Dictionaries oder so. Das hier funktioniert\n",
        "videos_df = pd.DataFrame(metadata['entries'][0]['entries'], columns=[\"id\",\"upload_date\",\"description\",\"duration\",\"view_count\",\"average_rating\",\n",
        "                                                                     \"age_limit\",\"categories\",\"tags\"])\n",
        "\n",
        "# Liste exportieren\n",
        "videos_df.to_excel(\"video_liste.xlsx\")\n",
        "print(len(videos_df),\" Videos in der Playlist/Kanal-Startseite gefunden.\")\n",
        "videos_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Videos herunterladen\n",
        "\n",
        "*ACHTUNG*: Dieser Schritt dauert eine Weile - und bricht gern mal mit einem Fehler ab, weil Youtube dem youtube-dl-Skript gerne mal ein \"Darfste nicht!\" in den Weg wirft. **Falls youtube-dl mit einem Fehler abbricht, ruft die Funktion sich selbst noch mal neu auf.** Das stößt (zum Glück) irgendwann an Grenzen - bei zu vielen Rekursionen bricht Python ab. \n",
        "\n",
        "Dummerweise verliert das Colab-Notebook nach einer Zeit die virtuelle Maschine, und man muss alles nochmal von vorn starten - deshalb schaut der Code, welche Videos schon heruntergeladen sind, und macht da weiter, wo es zuletzt aufgehört hat. "
      ],
      "metadata": {
        "id": "UbSN80GEJIP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definiere den Download als Funktion - die sich im Fehlerfall rekursiv neu aufruft\n",
        "\n",
        "def download_mp3(videos_liste):\n",
        "    # Die Optionen, um neben den Metadaten gleich alle MP3-Dateien herunterzuladen: \n",
        "    ydl_opts = {'format': 'bestaudio/best',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'mp3',\n",
        "        'preferredquality': '128',\n",
        "    }],\n",
        "    'outtmpl': '%(id)s.%(ext)s', # Formatiere Dateinamen: id.mp3\n",
        "    }\n",
        "\n",
        "    # Leere Liste anlegen\n",
        "    new_urls = []\n",
        "    # Videos, für die es noch kein mp3 gibt, in die Liste\n",
        "    for id in videos_liste:\n",
        "        f = path + \"/\" + id + \".mp3\"\n",
        "        if not os.path.exists(f):\n",
        "            new_urls.append(id)\n",
        "\n",
        "    if len(new_urls) > 0:\n",
        "        print(\"Noch \",len(new_urls),\" Videos herunterladen...\")\n",
        "        # Die Liste an den Downloader verfüttern.\n",
        "        # Videos werden nach dem Download in MP3 gewandelt, das\n",
        "        # bestimmen die Parameter. \n",
        "        try: \n",
        "            with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "                    ydl.download(new_urls)\n",
        "        except:\n",
        "            # Fehler geworfen; versuch es nochmal\n",
        "            print(\"Versuche es nochmal...\")\n",
        "            download_mp3(videos_liste)\n",
        "\n",
        "    print(\"Alle Videos des Kanals heruntergeladen!\")\n",
        "    return(True)\n",
        "\n",
        "# Jetzt die Funktion ausführen\n",
        "download_mp3(videos_df[\"id\"])"
      ],
      "metadata": {
        "id": "B1SbNxEP_MHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die Audios liegen alle als MP3 im Ordner output - mit den Dateinamen (id).mp3. Jetzt alle an den STT-Konverter schicken. \n",
        "\n",
        "Wir versuchen hier an dieser Stelle mal, OpenAIs \"Whisper\" einzusetzen. \n",
        "\n",
        "Quelle: https://github.com/openai/whisper"
      ],
      "metadata": {
        "id": "BkyD58v0c0kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git "
      ],
      "metadata": {
        "id": "PEpDrgQoffBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wenn die Installation der Library von Github geklappt hat, ist die eigentliche Transkription ziemlich simpel: "
      ],
      "metadata": {
        "id": "xBKJ8nokdI9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "# Wie oben: Liste von allen\n",
        "new_urls = []\n",
        "for id in videos_df[\"id\"]:\n",
        "    f = path + \"/\" + id + \"_transcribe.txt\"\n",
        "    if not os.path.exists(f):\n",
        "        new_urls.append(id)\n",
        "\n",
        "print(len(new_urls),\" MP3-Dateien zu verschriftlichen.\")\n",
        "\n",
        "for id in new_urls:\n",
        "    mp3_fname = path + \"/\" + id + \".mp3\"\n",
        "    txt_fname = path + \"/\" + id + \"_transcribe.txt\"\n",
        "\n",
        "    result = model.transcribe(mp3_fname)\n",
        "    # Ergebnis der Umwandlung als Textdatei ausgeben\n",
        "    with open(txt_fname, 'w') as f:\n",
        "      f.write(result[\"text\"])\n",
        "    print(txt_fname,\" erzeugt\")\n",
        "\n",
        "print(\"Fertig - \",len(new_urls),\" Dateien konvertiert.\")"
      ],
      "metadata": {
        "id": "wwP0tQN_dHaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}